{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.base import clone\n",
    "import timeit\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(F, X):\n",
    "    n, d = X.shape\n",
    "    mu = np.zeros((d, 1))\n",
    "    Z = np.zeros((d, F))\n",
    "    for i in range(d):\n",
    "        mu[i] = (1. / n) * np.sum(X[:, [i]])\n",
    "    X = X - mu.T\n",
    "    U, s, Vt = la.svd(X, False)\n",
    "    g = s[:F]\n",
    "    for i in range(F):\n",
    "        g[i] = 1. / g[i]\n",
    "    W = Vt[:F]\n",
    "    Z = np.dot(W.T, np.diag(g))\n",
    "    return (mu, Z)\n",
    "\n",
    "def pca_proj(X,mu,Z):\n",
    "    n, d = X.shape\n",
    "    X = X - mu.T\n",
    "    return np.dot(X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, model, X, y):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((k, 1))\n",
    "    for i in range(k):\n",
    "        T = list(range(int((i * n) / k), int((n * (i + 1) / k))))\n",
    "        S = [j for j in range(n) if j not in T]\n",
    "        curr_model = clone(model)\n",
    "        curr_model.fit(X[S], y[S])\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(X[T])) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(B, model, X, y):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((B, 1))\n",
    "    for i in range(B):\n",
    "        u = np.random.choice(n, n, replace=True)\n",
    "        S = np.unique(u)\n",
    "        T = np.setdiff1d(np.arange(n), S, assume_unique=True)\n",
    "        curr_model = clone(model)\n",
    "        curr_model.fit(X[u], y[u])\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        # theta_hat will be d by 1\n",
    "        z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(X[T])) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, f, X, y, k=5, B=5):\n",
    "    ######################## KFOLD ###################\n",
    "    print('Evaluating K-fold with %d folds.' % k)\n",
    "    start_time = timeit.default_timer()\n",
    "    k_fold_z = k_fold(k, model, f, X, y, error_type=\"log_mse\")\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    k_fold_mse = np.mean(k_fold_z)\n",
    "    print('K-fold Mean Squared log Error: ', k_fold_mse)\n",
    "    \n",
    "    k_fold_rmse = math.sqrt(k_fold_mse)\n",
    "    print('K-fold Square Root Mean Squared log Error: ', k_fold_rmse)\n",
    "\n",
    "    print(\"Time elapsed for k-fold: \", elapsed)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    ################### BOOTSTRAPPING ################\n",
    "    print('Evaluating bootstrapping with %d bootstraps.' % B)\n",
    "    start_time = timeit.default_timer()\n",
    "    bootstrapping_z = bootstrapping(B, model, f, X, y)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "    bootstrapping_mse = np.mean(bootstrapping_z)\n",
    "    print('Bootstrapping Mean Squared Error: ', bootstrapping_mse)\n",
    "\n",
    "    bootstrapping_rmse = math.sqrt(bootstrapping_mse)\n",
    "    print(\"Time elapsed for bootstrapping: \", elapsed)\n",
    "    \n",
    "    return (k_fold_z, k_fold_mse, k_fold_rmse, bootstrapping_z, bootstrapping_mse, bootstrapping_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1460, 80)\n",
      "(1460, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", header=0)\n",
    "print(data.shape)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1:]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n"
     ]
    }
   ],
   "source": [
    "# this just sums up how many nulls per feature and divides to find percentage of nulls per feature\n",
    "# if over 50% null then print the feature\n",
    "data_keys = X.keys()\n",
    "for i, b in enumerate((X.isnull().sum() / X.shape[0]) > 0.5):\n",
    "    if b:\n",
    "        print(data_keys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(['Alley', 'MiscFeature', 'Fence', 'PoolQC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExterQual  ExterCond  BsmtQual  BsmtCond  HeatingQC  KitchenQual  \\\n",
       "0          4          3       4.0       3.0          5            4   \n",
       "1          3          3       4.0       3.0          5            3   \n",
       "2          4          3       4.0       3.0          5            4   \n",
       "3          3          3       3.0       4.0          4            4   \n",
       "4          4          3       4.0       3.0          5            4   \n",
       "\n",
       "   FireplaceQu  GarageQual  GarageCond  \n",
       "0          NaN         3.0         3.0  \n",
       "1          3.0         3.0         3.0  \n",
       "2          3.0         3.0         3.0  \n",
       "3          4.0         3.0         3.0  \n",
       "4          3.0         3.0         3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replaces categorical value in Quality columns with numerical scale\n",
    "qualityCols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "              'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "data[qualityCols].head()\n",
    "\n",
    "for col in qualityCols:\n",
    "    # NA is never used since all NA's got converted to NaN objects when pandas read in the csv\n",
    "    data[col] = data[col].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po':1, 'NA': 0})\n",
    "\n",
    "data[qualityCols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BsmtExposure', 'GarageCond', 'MSZoning', 'FireplaceQu', 'BsmtFinType2', 'PavedDrive', 'Functional', 'BsmtCond', 'LandSlope', 'SaleType', 'KitchenQual', 'GarageType', 'ExterQual', 'Utilities', 'LandContour', 'GarageFinish', 'Exterior1st', 'Electrical', 'Exterior2nd', 'HouseStyle', 'LotConfig', 'BsmtQual', 'PoolQC', 'SaleCondition', 'Alley', 'Heating', 'Condition1', 'MiscFeature', 'Foundation', 'Condition2', 'Neighborhood', 'HeatingQC', 'MasVnrType', 'RoofMatl', 'LotShape', 'BldgType', 'ExterCond', 'BsmtFinType1', 'CentralAir', 'RoofStyle', 'Street', 'GarageQual', 'Fence'}\n"
     ]
    }
   ],
   "source": [
    "# categorical columns\n",
    "catCols = set(list(X))-set(list(X._get_numeric_data()))\n",
    "print(catCols)\n",
    "\n",
    "#Fill Categorical Column Null values with 0\n",
    "for col in catCols:\n",
    "    data[col].fillna(0, inplace=True)\n",
    "\n",
    "#Fill numerical column null values with mean of column\n",
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one hot encoding on all categorical columns\n",
    "frames = []\n",
    "for col in catCols:\n",
    "    oneHot_encoded = pd.get_dummies(X[col])\n",
    "    oneHot_encoded = oneHot_encoded.add_prefix(col + '_is_')\n",
    "    frames.append(oneHot_encoded)\n",
    "\n",
    "X = X.drop(catCols, axis=1)\n",
    "\n",
    "X = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BsmtExposure_is_Av', 'BsmtExposure_is_Gd', 'BsmtExposure_is_Mn',\n",
       "       'BsmtExposure_is_No', 'GarageCond_is_Ex', 'GarageCond_is_Fa',\n",
       "       'GarageCond_is_Gd', 'GarageCond_is_Po', 'GarageCond_is_TA',\n",
       "       'MSZoning_is_C (all)',\n",
       "       ...\n",
       "       'Street_is_Pave', 'GarageQual_is_Ex', 'GarageQual_is_Fa',\n",
       "       'GarageQual_is_Gd', 'GarageQual_is_Po', 'GarageQual_is_TA',\n",
       "       'Fence_is_GdPrv', 'Fence_is_GdWo', 'Fence_is_MnPrv', 'Fence_is_MnWw'],\n",
       "      dtype='object', length=252)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 train test ratio\n",
    "test_size = 0.2\n",
    "# This function splits the training and target sets into random train and test subsets.\n",
    "# X_train and X_test are subsets of the training data\n",
    "# y_train and y_test are subsets the the target data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mu, X_Z = pca(F, X.values)\n",
    "X_pca = pca_proj(X.values, X_mu, X_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "(252, 50)\n",
      "(1460, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_mu.shape)\n",
    "print(X_Z.shape)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mu, X_train_Z = pca(F, X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "(252, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_mu.shape)\n",
    "print(X_train_Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 50)\n",
      "(292, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca_proj(X_train.values, X_train_mu, X_train_Z)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca_proj(X_test.values, X_train_mu, X_train_Z)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import copy\n",
    "\n",
    "def nnRMSE(nn, X, y, X_test, y_test):\n",
    "    train_pred = nn.predict(X)\n",
    "    test_pred = nn.predict(X_test)\n",
    "    \n",
    "    trainSE = 0\n",
    "    for i in range(len(train_pred)):\n",
    "        trainSE += (train_pred[i]-y[i])**2\n",
    "    \n",
    "    testSE = 0\n",
    "    for i in range(len(test_pred)):\n",
    "        testSE += (test_pred[i]-y_test[i])**2\n",
    "    \n",
    "    trainRMSE = np.sqrt(trainSE / len(train_pred))\n",
    "    testRMSE = np.sqrt(testSE / len(test_pred))\n",
    "    \n",
    "    return trainRMSE, testRMSE\n",
    "\n",
    "# Based on Early Stopping\n",
    "def nn_setBestWeights(nn, cvErrors, models):\n",
    "    model_idx = np.argmin(cvErrors)\n",
    "    nn.coefs_ = models[model_idx][0]\n",
    "    nn.intercepts_ = models[model_idx][1]\n",
    "    print(\"Loaded nn with weights of lowest model.\")\n",
    "\n",
    "# 80/20 training / cross_val split\n",
    "train_size = int(len(X_pca) * .8)\n",
    "nn_X_train_pca = X_pca[:train_size]\n",
    "nn_X_test_pca = X_pca[train_size:]\n",
    "nn_y_train_pca = Y.values.ravel()[:train_size]\n",
    "nn_y_test_pca = Y.values.ravel()[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train, test): (197025.5049622786, 199795.308294238)\n",
      "(Train, test): (52765.29572352412, 59715.32939736021)\n",
      "(Train, test): (39494.99968096905, 47930.32504759745)\n",
      "(Train, test): (39500.69437625668, 47608.204845985885)\n",
      "(Train, test): (39499.86080842582, 47496.89765291244)\n",
      "(Train, test): (39597.12948268359, 47696.686193593065)\n",
      "(Train, test): (39522.53833684413, 47404.029453365896)\n",
      "(Train, test): (39494.00674589041, 47824.53416350405)\n",
      "(Train, test): (39524.120430652554, 47894.29700136297)\n",
      "(Train, test): (39510.72950936185, 47638.574929508584)\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping Routine\n",
    "lr = 0.02 \n",
    "num_iters = 10\n",
    "nn = MLPRegressor(\n",
    "                    hidden_layer_sizes=(24,24,24,),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    learning_rate='adaptive',\n",
    "                    warm_start=True,\n",
    "                    max_iter=1,\n",
    "                    learning_rate_init=0.01,\n",
    "                    alpha=0.01)\n",
    "\n",
    "max_iters = 1000\n",
    "cvErrors = []\n",
    "models = []\n",
    "for i in range(max_iters):\n",
    "    nn.fit(nn_X_train_pca, nn_y_train_pca)\n",
    "    if i % 10 == 0:\n",
    "        error = nnRMSE(nn, nn_X_train_pca, nn_y_train_pca, nn_X_test_pca, nn_y_test_pca)\n",
    "        if i % 100 == 0 :\n",
    "            print(f\"(Train, test): {error}\")\n",
    "        models.append((copy.deepcopy(nn.coefs_), copy.deepcopy(nn.intercepts_)))\n",
    "        cvErrors.append(error[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nn with weights of lowest model.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b166ace29534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn_setBestWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnnRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_X_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_y_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_X_test_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_y_test_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "nn_setBestWeights(nn, cvErrors, models)\n",
    "nnRMSE(nn, nn_X_train_pca, nn_y_train_pca, nn_X_test_pca, nn_y_test_pca)\n",
    "evaluate_model(nn, f, X_pca, Y.values.ravel(), k=5, B=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes time\n",
    "def tune_hyperparameters():\n",
    "    adaboost_param_tuning = pd.DataFrame(columns=['parameter', 'rmse'])\n",
    "    xgb_param_tuning = pd.DataFrame(columns=['parameter', 'rmse'])    \n",
    "    svr_param_tuning = pd.DataFrame(columns=['parameter', 'rmse'])    \n",
    "\n",
    "    #Tuning n estimators parameter for boosting algorithms\n",
    "    for i in range(25,200,25):\n",
    "        print(\"Boosting: \" + str(i))\n",
    "        adaBoost = AdaBoostRegressor(n_estimators=i)\n",
    "        k_fold_rmse, k_fold_z, bootstrapping_z = evaluateModel(adaBoost, X_pca, Y.values.ravel(), k=5, B=5, verbose=False)\n",
    "        adaboost_param_tuning = adaboost_param_tuning.append({'parameter': i, 'rmse': k_fold_rmse}, ignore_index=True)\n",
    "        xgb = XGBRegressor(max_depth=3, learning_rate=0.2, booster='gbtree', n_estimators=i)\n",
    "        k_fold_rmse, k_fold_z, bootstrapping_z = evaluateModel(xgb, X_pca, Y.values.ravel(), k=5, B=5, verbose=False)\n",
    "        xgb_param_tuning = xgb_param_tuning.append({'parameter': i, 'rmse': k_fold_rmse}, ignore_index=True)\n",
    "        \n",
    "    #for i in range(25,200,25):\n",
    "    c_vals = [0.01, 0.1, 10, 100]\n",
    "    for i in c_vals:\n",
    "        print(\"C: \" + str(i))\n",
    "        svr_model = svm.SVR(kernel=\"poly\", coef0=-3500, gamma=\"auto\", C=i)\n",
    "        evaluateModel(svr_model, X_pca, Y.values.ravel(), k=5, B=5, verbose=False)\n",
    "        svr_param_tuning = svr_param_tuning.append({'parameter': i, 'rmse': k_fold_rmse}, ignore_index=True)\n",
    "\n",
    "    return xgb_param_tuning, adaboost_param_tuning, svr_param_tuning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params, adaboost_params, svm_params = tune_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(estimator=adaBoost, title=\"Learning Curves (AdaBoost)\", X=X_train_pca, y=y_train, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "plot_learning_curve(estimator=xgb, title=\"Learning Curves (XgBoost)\", X=X_train_pca, y=y_train, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "plot_learning_curve(estimator=svr_model, title=\"Learning Curves (SVR)\", X=X_train_pca, y=y_train, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(predicted, name):\n",
    "    colors = [\"r\", \"b\"]\n",
    "    plt.title(name + \" Predicted vs Actual Sale Price\")\n",
    "    plt.xlabel(\"Actual Sale Price\")\n",
    "    plt.ylabel(\"Predicted Sale Price\")\n",
    "    red_patch = mpatches.Patch(color='red', label='Actual Sale Price')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Predicted Sale Price')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    plt.scatter(predicted['SalePrice'], predicted['predicted'], color=colors, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(ada_pred, \"AdaBoost\")\n",
    "plotScatter(xgb_pred, \"XgBoost\")\n",
    "plotScatter(svr_pred, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_tuning(xgb_params, adaboost_params, svm_params):\n",
    "    plt.plot(adaboost_params['parameter'], adaboost_params['rmse'], marker='o', color='b')\n",
    "    plt.title(\"Adaboost RMSE vs n_estimators\")\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(xgb_params['parameter'], xgb_params['rmse'], marker='o', color='b')\n",
    "    plt.title(\"XgBoost RMSE vs n_estimators\")\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(svm_params['parameter'], svm_params['rmse'], marker='o', color='b')\n",
    "    plt.title(\"SVM RMSE vs C\")\n",
    "    plt.xlabel(\"C\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_tuning(xgb_params, adaboost_params, svm_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
