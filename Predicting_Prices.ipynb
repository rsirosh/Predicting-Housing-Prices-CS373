{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "import timeit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca(F, X):\n",
    "    n, d = X.shape\n",
    "    mu = np.zeros((d, 1))\n",
    "    Z = np.zeros((d, F))\n",
    "    for i in range(d):\n",
    "        mu[i] = (1. / n) * np.sum(X[:, [i]])\n",
    "    X = X - mu.T\n",
    "    U, s, Vt = la.svd(X, False)\n",
    "    g = s[:F]\n",
    "    for i in range(F):\n",
    "        g[i] = 1. / g[i]\n",
    "    W = Vt[:F]\n",
    "    Z = np.dot(W.T, np.diag(g))\n",
    "    return (mu, Z)\n",
    "\n",
    "def pca_proj(X,mu,Z):\n",
    "    n, d = X.shape\n",
    "    X = X - mu.T\n",
    "    return np.dot(X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold(k, model, f, X, y, error_type=\"mse\"):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((k, 1))\n",
    "    for i in range(k):\n",
    "        T = list(range(int((i * n) / k), int((n * (i + 1) / k))))\n",
    "        S = [j for j in range(n) if j not in T]\n",
    "        curr_model = clone(model)\n",
    "\n",
    "        training_mu, training_Z = pca(f, X[S])\n",
    "        training_X = pca_proj(X[S], training_mu, training_Z)\n",
    "\n",
    "        curr_model.fit(training_X, y[S])\n",
    "\n",
    "        test_X = pca_proj(X[T], training_mu, training_Z)\n",
    "\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        if error_type == \"mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(test_X)) ** 2)\n",
    "        elif error_type == \"log_mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((np.log(y[T] + 1) - np.log(curr_model.predict(test_X) + 1)) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrapping(B, model, f, X, y, error_type=\"mse\"):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((B, 1))\n",
    "    for i in range(B):\n",
    "        u = np.random.choice(n, n, replace=True)\n",
    "        S = np.unique(u)\n",
    "        T = np.setdiff1d(np.arange(n), S, assume_unique=True)\n",
    "        curr_model = clone(model)\n",
    "\n",
    "        training_mu, training_Z = pca(f, X[u])\n",
    "        training_X = pca_proj(X[u], training_mu, training_Z)\n",
    "\n",
    "        curr_model.fit(training_X, y[u])\n",
    "\n",
    "        test_X = pca_proj(X[T], training_mu, training_Z)\n",
    "\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        # theta_hat will be d by 1\n",
    "        if error_type == \"mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(test_X)) ** 2)\n",
    "        elif error_type == \"log_mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((np.log(y[T] + 1) - np.log(curr_model.predict(test_X) + 1)) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, f, X, y, k=5, B=5):\n",
    "    ########################KFOLD###################\n",
    "    print('Evaluating K-fold with %d folds.' % k)\n",
    "    start_time = timeit.default_timer()\n",
    "    k_fold_z = k_fold(k, model, f, X, y, error_type=\"log_mse\")\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    k_fold_mse = np.mean(k_fold_z)\n",
    "    print('K-fold Mean Squared log Error: ', k_fold_mse)\n",
    "    \n",
    "    k_fold_rmse = math.sqrt(k_fold_mse)\n",
    "    print('K-fold Square Root Mean Squared log Error: ', k_fold_rmse)\n",
    "\n",
    "    print(\"Time elapsed for k-fold: \", elapsed)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    ###################BOOTSTRAPPING################\n",
    "    print('Evaluating bootstrapping with %d bootstraps.' % B)\n",
    "    start_time = timeit.default_timer()\n",
    "    bootstrapping_z = bootstrapping(B, model, f, X, y)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    bootstrapping_mse = np.mean(bootstrapping_z)\n",
    "    print('Bootstrapping Mean Squared Error: ', bootstrapping_mse)\n",
    "    \n",
    "    bootstrapping_rmse = math.sqrt(bootstrapping_mse)\n",
    "    print('Bootstrapping Square Root Mean Squared Error: ', bootstrapping_rmse)\n",
    "\n",
    "    print(\"Time elapsed for bootstrapping: \", elapsed)\n",
    "    \n",
    "    return (k_fold_z, k_fold_mse, k_fold_rmse, bootstrapping_z, bootstrapping_mse, bootstrapping_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "            ...\n",
       "            1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460],\n",
       "           dtype='int64', length=2920)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.append(data).index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1460, 80)\n",
      "(1460, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train = pd.read_csv(\"train.csv\", header=0)\n",
    "data_test = pd.read_csv(\"train.csv\", header=0)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1:]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n"
     ]
    }
   ],
   "source": [
    "# this just sums up how many nulls per feature and divides to find percentage of nulls per feature\n",
    "# if over 50% null then print the feature\n",
    "data_keys = X.keys()\n",
    "for i, b in enumerate((X.isnull().sum() / X.shape[0]) > 0.5):\n",
    "    if b:\n",
    "        print(data_keys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.drop(['Alley', 'MiscFeature', 'Fence', 'PoolQC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replaces categorical value in Quality columns with numerical scale\n",
    "# qualityCols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "#               'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "# X[qualityCols].head()\n",
    "\n",
    "# for col in qualityCols:\n",
    "#     # NA is never used since all NA's got converted to NaN objects when pandas read in the csv\n",
    "#     X[col] = X[col].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po':1, 'NA': 0})\n",
    "\n",
    "# X[qualityCols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PoolQC', 'Heating', 'LandSlope', 'SaleType', 'GarageQual', 'ExterCond', 'Utilities', 'MSZoning', 'ExterQual', 'BsmtFinType2', 'BsmtFinType1', 'Alley', 'Exterior2nd', 'GarageCond', 'BsmtQual', 'BldgType', 'Neighborhood', 'Exterior1st', 'RoofStyle', 'PavedDrive', 'BsmtExposure', 'Fence', 'MiscFeature', 'SaleCondition', 'Functional', 'Condition2', 'Foundation', 'GarageType', 'FireplaceQu', 'LandContour', 'BsmtCond', 'LotShape', 'HeatingQC', 'MasVnrType', 'KitchenQual', 'HouseStyle', 'GarageFinish', 'Street', 'RoofMatl', 'Electrical', 'CentralAir', 'LotConfig', 'Condition1'}\n"
     ]
    }
   ],
   "source": [
    "# categorical columns\n",
    "catCols = set(list(X))-set(list(X._get_numeric_data()))\n",
    "print(catCols)\n",
    "\n",
    "# #TRY dropping all cat cols\n",
    "# data = data.drop(columns=catCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(catCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform one hot encoding on all categorical columns\n",
    "frames = []\n",
    "for col in catCols:\n",
    "    oneHot_encoded = pd.get_dummies(X[col])\n",
    "    oneHot_encoded = oneHot_encoded.add_prefix(col + '_is_')\n",
    "    frames.append(oneHot_encoded)\n",
    "\n",
    "X = X.drop(catCols, axis=1)\n",
    "\n",
    "X = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PoolQC_is_Ex', 'PoolQC_is_Fa', 'PoolQC_is_Gd', 'Heating_is_Floor',\n",
       "       'Heating_is_GasA', 'Heating_is_GasW', 'Heating_is_Grav',\n",
       "       'Heating_is_OthW', 'Heating_is_Wall', 'LandSlope_is_Gtl',\n",
       "       ...\n",
       "       'LotConfig_is_Inside', 'Condition1_is_Artery', 'Condition1_is_Feedr',\n",
       "       'Condition1_is_Norm', 'Condition1_is_PosA', 'Condition1_is_PosN',\n",
       "       'Condition1_is_RRAe', 'Condition1_is_RRAn', 'Condition1_is_RRNe',\n",
       "       'Condition1_is_RRNn'],\n",
       "      dtype='object', length=252)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80:20 train test ratio\n",
    "test_size = 0.2\n",
    "# This function splits the training and target sets into random train and test subsets.\n",
    "# X_train and X_test are subsets of the training data\n",
    "# y_train and y_test are subsets the the target data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = 50\n",
    "f = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mu, X_Z = pca(F, X.values)\n",
    "X_pca = pca_proj(X.values, X_mu, X_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "(252, 50)\n",
      "(1460, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_mu.shape)\n",
    "print(X_Z.shape)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dc5d5406f7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_Z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_mu, X_train_Z = pca(F, X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_mu.shape)\n",
    "print(X_train_Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca_proj(X_train.values, X_train_mu, X_train_Z)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca_proj(X_test.values, X_train_mu, X_train_Z)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adaBoost = AdaBoostRegressor()\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(adaBoost, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "adaBoost.fit(X_train_pca, y_train.values.ravel())\n",
    "adaBoost.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Predicted values\n",
    "predicted = adaBoost.predict(X_test_pca)\n",
    "ada_pred = y_test.copy()\n",
    "ada_pred['predicted'] = predicted\n",
    "ada_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(max_depth=3, learning_rate=0.2, booster='gbtree', n_estimators=70)\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(xgb, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "xgb.fit(X_train_pca, y_train)\n",
    "xgb.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = xgb.predict(X_test_pca)\n",
    "xgb_pred = y_test.copy()\n",
    "xgb_pred['predicted'] = predicted\n",
    "xgb_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svr_model = svm.SVR(kernel=\"poly\", coef0=-3500, gamma=\"auto\")\n",
    "# coef0 only works with poly and sigmoid kernels\n",
    "# it just puts that value instead of the column of 1's\n",
    "\n",
    "# without it, this model breaks for some reason\n",
    "\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(svr_model, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "# epsilon, degree\n",
    "svr_model.fit(X_train_pca, y_train.values.ravel())\n",
    "svr_model.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_predicted = svr_model.predict(X_test_pca)\n",
    "svr_pred = y_test.copy()\n",
    "svr_pred[\"predicted\"] = svr_predicted\n",
    "svr_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost seems the best so let's use it to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle = pd.read_csv(\"test.csv\", header=0)\n",
    "print(data_kaggle.shape)\n",
    "\n",
    "X_kaggle_test = data_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one hot encoding on all categorical columns\n",
    "frames_kaggle = []\n",
    "for col in catCols:\n",
    "    oneHot_encoded_kaggle = pd.get_dummies(X_kaggle_test[col])\n",
    "    oneHot_encoded_kaggle = oneHot_encoded_kaggle.add_prefix(col + '_is_')\n",
    "    frames_kaggle.append(oneHot_encoded_kaggle)\n",
    "\n",
    "X_kaggle_test = X_kaggle_test.drop(catCols, axis=1)\n",
    "\n",
    "X_kaggle_test = pd.concat(frames_kaggle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_kaggle_test_pca = pca_proj(X_kaggle_test.values, X_mu, X_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(max_depth=3, learning_rate=0.2, booster='gbtree', n_estimators=70)\n",
    "xgb.fit(X_pca, Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = xgb.predict(X_kaggle_test_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
