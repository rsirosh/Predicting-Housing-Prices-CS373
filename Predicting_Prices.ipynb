{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "import timeit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca(F, X):\n",
    "    n, d = X.shape\n",
    "    mu = np.zeros((d, 1))\n",
    "    Z = np.zeros((d, F))\n",
    "    for i in range(d):\n",
    "        mu[i] = (1. / n) * np.sum(X[:, [i]])\n",
    "    X = X - mu.T\n",
    "    U, s, Vt = la.svd(X, False)\n",
    "    g = s[:F]\n",
    "    for i in range(F):\n",
    "        g[i] = 1. / g[i]\n",
    "    W = Vt[:F]\n",
    "    Z = np.dot(W.T, np.diag(g))\n",
    "    return (mu, Z)\n",
    "\n",
    "def pca_proj(X,mu,Z):\n",
    "    n, d = X.shape\n",
    "    X = X - mu.T\n",
    "    return np.dot(X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold(k, model, f, X, y, error_type=\"mse\"):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((k, 1))\n",
    "    for i in range(k):\n",
    "        T = list(range(int((i * n) / k), int((n * (i + 1) / k))))\n",
    "        S = [j for j in range(n) if j not in T]\n",
    "        curr_model = clone(model)\n",
    "\n",
    "        training_mu, training_Z = pca(f, X[S])\n",
    "        training_X = pca_proj(X[S], training_mu, training_Z)\n",
    "\n",
    "        curr_model.fit(training_X, y[S])\n",
    "\n",
    "        test_X = pca_proj(X[T], training_mu, training_Z)\n",
    "\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        if error_type == \"mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(test_X)) ** 2)\n",
    "        elif error_type == \"log_mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((np.log(y[T] + 1) - np.log(curr_model.predict(test_X) + 1)) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrapping(B, model, f, X, y, error_type=\"mse\"):\n",
    "    n, d = X.shape\n",
    "    z = np.zeros((B, 1))\n",
    "    for i in range(B):\n",
    "        u = np.random.choice(n, n, replace=True)\n",
    "        S = np.unique(u)\n",
    "        T = np.setdiff1d(np.arange(n), S, assume_unique=True)\n",
    "        curr_model = clone(model)\n",
    "\n",
    "        training_mu, training_Z = pca(f, X[u])\n",
    "        training_X = pca_proj(X[u], training_mu, training_Z)\n",
    "\n",
    "        curr_model.fit(training_X, y[u])\n",
    "\n",
    "        test_X = pca_proj(X[T], training_mu, training_Z)\n",
    "\n",
    "        # y[T] will be len(T) by 1\n",
    "        # X[T] will be len(T) by d\n",
    "        # theta_hat will be d by 1\n",
    "        if error_type == \"mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((y[T] - curr_model.predict(test_X)) ** 2)\n",
    "        elif error_type == \"log_mse\":\n",
    "            z[i] = (1. / len(T)) * np.sum((np.log(y[T] + 1) - np.log(curr_model.predict(test_X) + 1)) ** 2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, f, X, y, k=5, B=5):\n",
    "    ########################KFOLD###################\n",
    "    print('Evaluating K-fold with %d folds.' % k)\n",
    "    start_time = timeit.default_timer()\n",
    "    k_fold_z = k_fold(k, model, f, X, y, error_type=\"log_mse\")\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    k_fold_mse = np.mean(k_fold_z)\n",
    "    print('K-fold Mean Squared log Error: ', k_fold_mse)\n",
    "    \n",
    "    k_fold_rmse = math.sqrt(k_fold_mse)\n",
    "    print('K-fold Square Root Mean Squared log Error: ', k_fold_rmse)\n",
    "\n",
    "    print(\"Time elapsed for k-fold: \", elapsed)\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    ###################BOOTSTRAPPING################\n",
    "    print('Evaluating bootstrapping with %d bootstraps.' % B)\n",
    "    start_time = timeit.default_timer()\n",
    "    bootstrapping_z = bootstrapping(B, model, f, X, y)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    bootstrapping_mse = np.mean(bootstrapping_z)\n",
    "    print('Bootstrapping Mean Squared Error: ', bootstrapping_mse)\n",
    "    \n",
    "    bootstrapping_rmse = math.sqrt(bootstrapping_mse)\n",
    "    print('Bootstrapping Square Root Mean Squared Error: ', bootstrapping_rmse)\n",
    "\n",
    "    print(\"Time elapsed for bootstrapping: \", elapsed)\n",
    "    \n",
    "    return (k_fold_z, k_fold_mse, k_fold_rmse, bootstrapping_z, bootstrapping_mse, bootstrapping_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1460, 80)\n",
      "(1460, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", header=0)\n",
    "print(data.shape)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1:]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n"
     ]
    }
   ],
   "source": [
    "# this just sums up how many nulls per feature and divides to find percentage of nulls per feature\n",
    "# if over 50% null then print the feature\n",
    "data_keys = X.keys()\n",
    "for i, b in enumerate((X.isnull().sum() / X.shape[0]) > 0.5):\n",
    "    if b:\n",
    "        print(data_keys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.drop(['Alley', 'MiscFeature', 'Fence', 'PoolQC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replaces categorical value in Quality columns with numerical scale\n",
    "# qualityCols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "#               'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "# X[qualityCols].head()\n",
    "\n",
    "# for col in qualityCols:\n",
    "#     # NA is never used since all NA's got converted to NaN objects when pandas read in the csv\n",
    "#     X[col] = X[col].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po':1, 'NA': 0})\n",
    "\n",
    "# X[qualityCols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Condition1', 'ExterQual', 'FireplaceQu', 'MiscFeature', 'Neighborhood', 'HouseStyle', 'BsmtFinType2', 'LotShape', 'RoofMatl', 'Utilities', 'MasVnrType', 'BsmtCond', 'CentralAir', 'GarageQual', 'BldgType', 'BsmtExposure', 'RoofStyle', 'PavedDrive', 'LotConfig', 'GarageFinish', 'Heating', 'LandContour', 'ExterCond', 'Street', 'BsmtQual', 'Electrical', 'Condition2', 'Exterior2nd', 'PoolQC', 'LandSlope', 'GarageType', 'KitchenQual', 'SaleCondition', 'Alley', 'MSZoning', 'Exterior1st', 'Functional', 'Foundation', 'BsmtFinType1', 'GarageCond', 'Fence', 'HeatingQC', 'SaleType'}\n"
     ]
    }
   ],
   "source": [
    "# categorical columns\n",
    "catCols = set(list(X))-set(list(X._get_numeric_data()))\n",
    "print(catCols)\n",
    "\n",
    "# #TRY dropping all cat cols\n",
    "# data = data.drop(columns=catCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform one hot encoding on all categorical columns\n",
    "frames = []\n",
    "for col in catCols:\n",
    "    oneHot_encoded = pd.get_dummies(X[col])\n",
    "    oneHot_encoded = oneHot_encoded.add_prefix(col + '_is_')\n",
    "    frames.append(oneHot_encoded)\n",
    "\n",
    "X = X.drop(catCols, axis=1)\n",
    "\n",
    "X = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Condition1_is_Artery', 'Condition1_is_Feedr', 'Condition1_is_Norm',\n",
       "       'Condition1_is_PosA', 'Condition1_is_PosN', 'Condition1_is_RRAe',\n",
       "       'Condition1_is_RRAn', 'Condition1_is_RRNe', 'Condition1_is_RRNn',\n",
       "       'ExterQual_is_Ex',\n",
       "       ...\n",
       "       'HeatingQC_is_TA', 'SaleType_is_COD', 'SaleType_is_CWD',\n",
       "       'SaleType_is_Con', 'SaleType_is_ConLD', 'SaleType_is_ConLI',\n",
       "       'SaleType_is_ConLw', 'SaleType_is_New', 'SaleType_is_Oth',\n",
       "       'SaleType_is_WD'],\n",
       "      dtype='object', length=252)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80:20 train test ratio\n",
    "test_size = 0.2\n",
    "# This function splits the training and target sets into random train and test subsets.\n",
    "# X_train and X_test are subsets of the training data\n",
    "# y_train and y_test are subsets the the target data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = 50\n",
    "f = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mu, X_Z = pca(F, X.values)\n",
    "X_pca = pca_proj(X.values, X_mu, X_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "(252, 50)\n",
      "(1460, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_mu.shape)\n",
    "print(X_Z.shape)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_mu, X_train_Z = pca(F, X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "(252, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_mu.shape)\n",
    "print(X_train_Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 50)\n",
      "(292, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca_proj(X_train.values, X_train_mu, X_train_Z)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca_proj(X_test.values, X_train_mu, X_train_Z)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating K-fold with 5 folds.\n",
      "K-fold Mean Squared log Error:  0.0863238411416\n",
      "K-fold Square Root Mean Squared log Error:  0.2938091917240796\n",
      "Time elapsed for k-fold:  5.4119528\n",
      "\n",
      "\n",
      "Evaluating bootstrapping with 5 bootstraps.\n",
      "Bootstrapping Mean Squared Error:  2954947094.39\n",
      "Bootstrapping Square Root Mean Squared Error:  54359.425074130515\n",
      "Time elapsed for bootstrapping:  6.112511199999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63078892308865608"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adaBoost = AdaBoostRegressor()\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(adaBoost, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "adaBoost.fit(X_train_pca, y_train.values.ravel())\n",
    "adaBoost.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>155000</td>\n",
       "      <td>146194.506203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>155000</td>\n",
       "      <td>172181.563981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>113000</td>\n",
       "      <td>134192.379205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>187000</td>\n",
       "      <td>227937.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>274900</td>\n",
       "      <td>336290.652174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice      predicted\n",
       "818      155000  146194.506203\n",
       "1296     155000  172181.563981\n",
       "555      113000  134192.379205\n",
       "992      187000  227937.773333\n",
       "199      274900  336290.652174"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Predicted values\n",
    "predicted = adaBoost.predict(X_test_pca)\n",
    "ada_pred = y_test.copy()\n",
    "ada_pred['predicted'] = predicted\n",
    "ada_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating K-fold with 5 folds.\n",
      "K-fold Mean Squared log Error:  0.0485028647496\n",
      "K-fold Square Root Mean Squared log Error:  0.22023365943827247\n",
      "Time elapsed for k-fold:  2.841487899999999\n",
      "\n",
      "\n",
      "Evaluating bootstrapping with 5 bootstraps.\n",
      "Bootstrapping Mean Squared Error:  2005284003.48\n",
      "Bootstrapping Square Root Mean Squared Error:  44780.39753594813\n",
      "Time elapsed for bootstrapping:  3.4412237999999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70327558378028088"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(max_depth=3, learning_rate=0.2, booster='gbtree', n_estimators=70)\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(xgb, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "xgb.fit(X_train_pca, y_train)\n",
    "xgb.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>155000</td>\n",
       "      <td>154907.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>155000</td>\n",
       "      <td>150216.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>113000</td>\n",
       "      <td>128500.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>187000</td>\n",
       "      <td>175113.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>274900</td>\n",
       "      <td>371756.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice      predicted\n",
       "818      155000  154907.546875\n",
       "1296     155000  150216.578125\n",
       "555      113000  128500.031250\n",
       "992      187000  175113.140625\n",
       "199      274900  371756.312500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = xgb.predict(X_test_pca)\n",
    "xgb_pred = y_test.copy()\n",
    "xgb_pred['predicted'] = predicted\n",
    "xgb_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating K-fold with 5 folds.\n",
      "K-fold Mean Squared log Error:  0.054210540666\n",
      "K-fold Square Root Mean Squared log Error:  0.23283157145453767\n",
      "Time elapsed for k-fold:  2.0605405999999995\n",
      "\n",
      "\n",
      "Evaluating bootstrapping with 5 bootstraps.\n",
      "Bootstrapping Mean Squared Error:  2532535920.18\n",
      "Bootstrapping Square Root Mean Squared Error:  50324.30744854705\n",
      "Time elapsed for bootstrapping:  2.895757400000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70304689818503441"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svr_model = svm.SVR(kernel=\"poly\", coef0=-3500, gamma=\"auto\")\n",
    "# coef0 only works with poly and sigmoid kernels\n",
    "# it just puts that value instead of the column of 1's\n",
    "\n",
    "# without it, this model breaks for some reason\n",
    "\n",
    "k_z, k_mse, k_rmse, b_z, b_mse, b_rmse = evaluate_model(svr_model, f, X.values, Y.values.ravel(), k=5, B=5)\n",
    "\n",
    "# epsilon, degree\n",
    "svr_model.fit(X_train_pca, y_train.values.ravel())\n",
    "svr_model.score(X_test_pca, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>155000</td>\n",
       "      <td>181326.349284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>155000</td>\n",
       "      <td>179206.964198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>113000</td>\n",
       "      <td>136460.572245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>187000</td>\n",
       "      <td>217230.809878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>274900</td>\n",
       "      <td>315125.702647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice      predicted\n",
       "818      155000  181326.349284\n",
       "1296     155000  179206.964198\n",
       "555      113000  136460.572245\n",
       "992      187000  217230.809878\n",
       "199      274900  315125.702647"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_predicted = svr_model.predict(X_test_pca)\n",
    "svr_pred = y_test.copy()\n",
    "svr_pred[\"predicted\"] = svr_predicted\n",
    "svr_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost seems the best so let's use it to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "data_kaggle = pd.read_csv(\"test.csv\", header=0)\n",
    "print(data_kaggle.shape)\n",
    "\n",
    "X_kaggle_test = data_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just sums up how many nulls per feature and divides to find percentage of nulls per feature\n",
    "# if over 50% null then print the feature\n",
    "data_keys = X_kaggle_test.keys()\n",
    "for i, b in enumerate((X_kaggle_test.isnull().sum() / X_kaggle_test.shape[0]) > 0.5):\n",
    "    if b:\n",
    "        print(data_kaggle[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replaces categorical value in Quality columns with numerical scale\n",
    "# qualityCols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "#               'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "\n",
    "# X[qualityCols].head()\n",
    "\n",
    "# for col in qualityCols:\n",
    "#     # NA is never used since all NA's got converted to NaN objects when pandas read in the csv\n",
    "#     X[col] = X[col].map({'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po':1, 'NA': 0})\n",
    "\n",
    "# X[qualityCols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# categorical columns\n",
    "catCols = set(list(X))-set(list(X._get_numeric_data()))\n",
    "print(catCols)\n",
    "\n",
    "# #TRY dropping all cat cols\n",
    "# data = data.drop(columns=catCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-1112ed8e481a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcatCols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                        copy=copy)\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#Perform one hot encoding on all categorical columns\n",
    "frames = []\n",
    "for col in catCols:\n",
    "    oneHot_encoded = pd.get_dummies(X[col])\n",
    "    oneHot_encoded = oneHot_encoded.add_prefix(col + '_is_')\n",
    "    frames.append(oneHot_encoded)\n",
    "\n",
    "X = X.drop(catCols, axis=1)\n",
    "\n",
    "X = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 train test ratio\n",
    "test_size = 0.2\n",
    "# This function splits the training and target sets into random train and test subsets.\n",
    "# X_train and X_test are subsets of the training data\n",
    "# y_train and y_test are subsets the the target data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = 50\n",
    "f = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_mu, X_Z = pca(F, X.values)\n",
    "X_pca = pca_proj(X.values, X_mu, X_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_mu.shape)\n",
    "print(X_Z.shape)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_mu, X_train_Z = pca(F, X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train_mu.shape)\n",
    "print(X_train_Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca_proj(X_train.values, X_train_mu, X_train_Z)\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca_proj(X_test.values, X_train_mu, X_train_Z)\n",
    "print(X_test_pca.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
